{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f6259c1",
   "metadata": {},
   "source": [
    "# iLykei Lecture Series    \n",
    "# Text Analytics   \n",
    "# Assignment: Language Models\n",
    "## Yuri Balasanov, &copy; iLykei 2022     \n",
    "\n",
    "The following table shows the calculated bi-gram probabilities from Figure 3.2 Bigram in the text by D.Jurafsky, J.H. Martin. The probabilities based on the Berkeley Restaurant Project corpus of 9332 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a2ab49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92a5fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "tkns = [\"i\",\"want\",\"to\",\"eat\",\"chinese\",\"food\",\"lunch\",\"spend\"]\n",
    "\n",
    "tble = [[\"\"]+tkns,\n",
    "       [\"i\",\"0.002\", \"0.33\", \"0\", \"0.0036\", \"0\", \"0\", \"0\", \"0.00079\"],\n",
    "       [\"want\", \"0.0022\", \"0\", \"0.66\", \"0.0011\", \"0.0065\", \"0.0065\", \"0.0054\", \"0.0011\"],\n",
    "       [\"to\", \"0.00083\", \"0\", \"0.0017\", \"0.28\", \"0.00083\", \"0\", \"0.0025\", \"0.087\"],\n",
    "       [\"eat\", \"0\", \"0\", \"0.0027\", \"0\", \"0.021\", \"0.0027\", \"0.056\", \"0\"],\n",
    "       [\"chinese\", \"0.0063\", \"0\", \"0\", \"0\", \"0\", \"0.52\", \"0.0063\", \"0\"],\n",
    "       [\"food\", \"0.014\", \"0\", \"0.014\", \"0\", \"0.00092\", \"0.0037\", \"0\", \"0\"],\n",
    "       [\"lunch\", \"0.0059\", \"0\", \"0\", \"0\", \"0\", \"0.0029\", \"0\", \"0\"],\n",
    "       [\"spend\", \"0.0036\", \"0\", \"0.0036\", \"0\", \"0\", \"0\", \"0\", \"0\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2f23fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               i    want      to     eat    chinese    food    lunch    spend\n",
      "-------  -------  ------  ------  ------  ---------  ------  -------  -------\n",
      "i        0.002      0.33  0       0.0036    0        0        0       0.00079\n",
      "want     0.0022     0     0.66    0.0011    0.0065   0.0065   0.0054  0.0011\n",
      "to       0.00083    0     0.0017  0.28      0.00083  0        0.0025  0.087\n",
      "eat      0          0     0.0027  0         0.021    0.0027   0.056   0\n",
      "chinese  0.0063     0     0       0         0        0.52     0.0063  0\n",
      "food     0.014      0     0.014   0         0.00092  0.0037   0       0\n",
      "lunch    0.0059     0     0       0         0        0.0029   0       0\n",
      "spend    0.0036     0     0.0036  0         0        0        0       0\n"
     ]
    }
   ],
   "source": [
    "print(tabulate(tble,headers=\"firstrow\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9754af55",
   "metadata": {},
   "source": [
    "The user request starts with \"i\", $P(\"i\"|<s>)=0.25$.   \n",
    "Using bi-gram language model with the probabilities in the table above predict 7 tokens following \"i\" one by one. Return the bi-gram language model probability of the predicted sequence, i.e. make the output in the form "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99689fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i    token    token    token    token    token    token    token    token\n",
      "---  -------  -------  -------  -------  -------  -------  -------  -------\n",
      "i    token_1                                                        prob_1\n",
      "i    token_1  token_2                                               prob_2\n",
      "i    token_1  token_2  token_3                                      prob_3\n",
      "i    token_1  token_2  token_3  token_4                             prob_4\n",
      "i    token_1  token_2  token_3  token_4  token_5                    prob_5\n",
      "i    token_1  token_2  token_3  token_4  token_5  token_6           prob_6\n",
      "i    token_1  token_2  token_3  token_4  token_5  token_6  token_7  prob_7\n"
     ]
    }
   ],
   "source": [
    "output=[['i','token','token','token','token','token','token','token','token','probability'],\n",
    "       ['i','token_1',\"\",\"\",\"\",\"\",\"\",\"\",'prob_1'],\n",
    "       ['i','token_1','token_2',\"\",\"\",\"\",\"\",\"\",'prob_2'],\n",
    "       ['i','token_1','token_2','token_3',\"\",\"\",\"\",\"\",'prob_3'],\n",
    "       ['i','token_1','token_2','token_3','token_4',\"\",\"\",\"\",'prob_4'],\n",
    "       ['i','token_1','token_2','token_3','token_4','token_5',\"\",\"\",'prob_5'],\n",
    "       ['i','token_1','token_2','token_3','token_4','token_5','token_6',\"\",'prob_6'],\n",
    "       ['i','token_1','token_2','token_3','token_4','token_5','token_6','token_7','prob_7']]\n",
    "\n",
    "print(tabulate(output,headers=\"firstrow\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}